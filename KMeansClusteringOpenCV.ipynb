{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KMeansClusteringOpenCV.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPQD3EIfN1cMpP3PKbrOryR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertofernandezvillan/computer-vision-and-deep-learning-course/blob/main/KMeansClusteringOpenCV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZSZDhJksrlG"
      },
      "source": [
        "#Import required packages:\r\n",
        "import numpy as np\r\n",
        "import cv2\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import collections\r\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MUx-vrfszXD"
      },
      "source": [
        "def color_quantization(image, k):\r\n",
        "    \"\"\"Performs color quantization using K-means clustering algorithm\"\"\"\r\n",
        "\r\n",
        "    # Transform image into 'data':\r\n",
        "    data = np.float32(image).reshape((-1, 3))\r\n",
        "\r\n",
        "    # Define the algorithm termination criteria (the maximum number of iterations and/or the desired accuracy):\r\n",
        "    # In this case the maximum number of iterations is set to 20 and epsilon = 1.0\r\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 1.0)\r\n",
        "\r\n",
        "    # Apply K-means clustering algorithm:\r\n",
        "    # ret, label, center = cv2.kmeans(data, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\r\n",
        "    ret, label, center = cv2.kmeans(data, k, None, criteria, 10, cv2.KMEANS_PP_CENTERS)\r\n",
        "    \r\n",
        "    # At this point we can make the image with k colors\r\n",
        "    # Convert center to uint8:\r\n",
        "    center = np.uint8(center)\r\n",
        "\r\n",
        "    # Replace pixel values with their center value:\r\n",
        "    result = center[label.flatten()]\r\n",
        "    result = result.reshape(image.shape)\r\n",
        "\r\n",
        "    # Build the 'color_distribution' legend.\r\n",
        "    # We will use the number of pixels assigned to each center value:\r\n",
        "    counter = collections.Counter(label.flatten())\r\n",
        "\r\n",
        "    # Calculate the total number of pixels of the input image:\r\n",
        "    total = image.shape[0] * image.shape[1]\r\n",
        "\r\n",
        "    # Assign width and height to the color_distribution image:\r\n",
        "    desired_width = image.shape[1]\r\n",
        "    # The difference between 'desired_height' and 'desired_height_colors'\r\n",
        "    # will be the separation between the images\r\n",
        "    desired_height = 70\r\n",
        "    desired_height_colors = 50\r\n",
        "\r\n",
        "    # Initialize the color_distribution image:\r\n",
        "    color_distribution = np.ones((desired_height, desired_width, 3), dtype=\"uint8\") * 255\r\n",
        "    # Initialize start:\r\n",
        "    start = 0\r\n",
        "\r\n",
        "    for key, value in counter.items():\r\n",
        "        # Calculate the normalized value:\r\n",
        "        value_normalized = value / total * desired_width\r\n",
        "\r\n",
        "        # Move end to the right position:\r\n",
        "        end = start + value_normalized\r\n",
        "\r\n",
        "        # Draw rectangle corresponding to the current color:\r\n",
        "        cv2.rectangle(color_distribution, (int(start), 0), (int(end), desired_height_colors), center[key].tolist(), -1)\r\n",
        "        # Update start:\r\n",
        "        start = end\r\n",
        "\r\n",
        "    return np.vstack((color_distribution, result))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XwRb0Gcs2YF"
      },
      "source": [
        "!wget \"https://raw.githubusercontent.com/albertofernandezvillan/computer-vision-and-deep-learning-course/main/assets/thermal-image.JPG\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK4FqQh_vTso"
      },
      "source": [
        "img = cv2.imread(\"thermal-image.JPG\")\r\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEKth_f2vovS"
      },
      "source": [
        "# Apply color quantization (K-means with K=2)\r\n",
        "img_result = color_quantization(img, 2)\r\n",
        "cv2_imshow(img_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-XRAq18vur-"
      },
      "source": [
        "# Apply bilateral filter to reduce noise in the input image:\r\n",
        "img_bilateral_blur = cv2.bilateralFilter(img, 100, 120, 120)\r\n",
        "cv2_imshow(img_bilateral_blur)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDniv5oxwDeJ"
      },
      "source": [
        "# Apply color quantization (K-means with K=2)\r\n",
        "img_result_bilateral_blur = color_quantization(img_bilateral_blur, 2)\r\n",
        "cv2_imshow(img_result_bilateral_blur)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}