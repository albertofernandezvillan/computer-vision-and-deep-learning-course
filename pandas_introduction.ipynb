{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pandas_introduction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPMYjopAUSOT9HsMXYc47F3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertofernandezvillan/computer-vision-and-deep-learning-course/blob/main/pandas_introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCmdWUGe2xmp"
      },
      "source": [
        "<img align=\"left\" style=\"padding-right:10px;\" src =\"https://raw.githubusercontent.com/albertofernandezvillan/computer-vision-and-deep-learning-course/main/assets/university_oviedo_logo.png\" width=300 px>\n",
        "\n",
        "This notebook is from the Course \"***Computer vision in the new era of Artificial Intelligence and Deep Learning***\", or \"*Visión por computador en la nueva era de la Inteligencia Artificial y el Deep Learning*\" (ES) from the \"Second quarter university extension courses\" that the University of Oviedo is offering (05/04/2021 - 16/04/2021)\n",
        "\n",
        "<[Github Repository](https://github.com/albertofernandezvillan/computer-vision-and-deep-learning-course) | [Course Web Page Information](https://www.uniovi.es/estudios/extension/cursos2c/-/asset_publisher/SEp0PJi4ISGo/content/vision-por-computador-en-la-nueva-era-de-la-inteligencia-artificial-y-el-deep-learning?redirect=%2Festudios%2Fextension%2Fcursos2c)>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7iB84H120MQ"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, a quick introduction to pandas is given. More specifically, we are going to cover:\n",
        "\n",
        "- Introduction to pandas\n",
        "- Pandas data table representation\n",
        "- Axis in Series and axes in DataFrames\n",
        "- Creating pandas DataFrames\n",
        "- DataFrame attributes\n",
        "- DataFrame methods\n",
        "\n",
        "In next notebooks we will cover some of these points in more detail. For example, how to select subsets of data in pandas, which is a key point to filter the data we want to analyze. Selecting subsets of data in pandas can be performed in different ways, but as commented before, this will be covered in other pandas notebook tutorials. In this notebook, only the basics will be covered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2VwpDZNXA7F"
      },
      "source": [
        "# Introduction to pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "079V9W68Xq8h"
      },
      "source": [
        "Pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language. In particular, it offers data structures and operations for manipulating numerical tables and time series.\n",
        "\n",
        "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/22/Pandas_mark.svg/128px-Pandas_mark.svg.png\"></center>\n",
        "\n",
        "To load the pandas package and start working with it, import the package:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "```\n",
        "\n",
        "The community agreed alias for pandas is `pd`, so loading pandas as `pd` is assumed standard practice for all of the pandas documentation.\n",
        "\n",
        "At the time of writing these tutorials installed version of pandas in Colab is `1.1.5` (release date: December 07, 2020), and latest version of pandas is `1.2.3` (release date: Mar 02, 2021). \n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "print(\"pandas version: '{}'\".format(pd.__version__))\n",
        "```\n",
        "\n",
        "`pandas version: '1.1.5'`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5SP40DVZYVX"
      },
      "source": [
        "# Pandas data table representation\n",
        "\n",
        "As commented in the introduction, pandas offers data structures that make data manipulation and analysis easy (among other thins). The [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) is one of these structures. The [Series](https://pandas.pydata.org/docs/reference/api/pandas.Series.html) is another usefull structure, but let's start with the DataFrame.\n",
        "\n",
        "In pandas, a data table is called a **DataFrame**. The short explanation about what is a DataFrame could be \"*a two-dimensional, size-mutable, potentially heterogeneous tabular data*\". It is generally the most commonly used pandas object.\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/albertofernandezvillan/computer-vision-and-deep-learning-course/main/assets/pandas_dataframe.png\" width=400></center>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMQ7xUAriN7P"
      },
      "source": [
        "Next Figure ([extracted from one of the best tutorials you will find about pandas](https://medium.com/dunder-data/selecting-subsets-of-data-in-pandas-6fcd0170be9c)), shows the anatomy of a DataFrame.\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/albertofernandezvillan/computer-vision-and-deep-learning-course/main/assets/dataframe_example.png\" width=900></center>\n",
        "\n",
        "A DataFrame is composed of three different components, the **index**, **columns**, and the **data**. The data is also known as the **values**.\n",
        "\n",
        "- The index in previous example are just the integers beginning from `0` up to `n-1`, where `n` is the number of rows in the table. Each individual value of the index is called a label.\n",
        "\n",
        "- The columns are the sequence of values at the very top of the DataFrame. Each individual value of the columns is called a column.\n",
        "\n",
        "- Everything else not in bold font is the data or values. As you can see, there are also missing values (represented as NaN).\n",
        "\n",
        "\n",
        "It is also common terminology to refer to the rows or columns as an axis. See next point for a quick introduction about axes.\n",
        "\n",
        "A pandas **Series** is a one-dimensional data structure that comprises of a key-value pair. It can be seen as a python dictionary, except it provides more freedom to manipulate and edit the data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9wI5GQBknK3"
      },
      "source": [
        "# Axis in Series and axes in DataFrames\n",
        "\n",
        "While DataFrames are two-dimensional structures, a Series is a one-dimensional structure. We will understand how axis works in Series and how axes work in DataFrames.\n",
        "\n",
        "Let's start with Series. As commented briefly above, series is a one-dimensional array of values. Under the hood, it uses numpy ndarray. That is where the term \"axis\" came from. Series object has only \"`axis 0`\" because it has only one dimension. \n",
        "\n",
        "Just as a note, usually, in Python, one-dimensional structures are displayed as a row of values. On the contrary, Series is displayed as a column of values. Let's compare a Series with a numpy array in the following example.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwaZ7EZlp4u4",
        "outputId": "78919289-3ba8-4228-f092-d0825b0bcd36"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "serie = pd.Series(['a','b','c'])\n",
        "print(\"serie shape: {}\".format(serie.shape))\n",
        "print(serie)\n",
        "print(\"second value of the serie (serie[1]): {}\".format(serie[1]))\n",
        "\n",
        "np_array = np.array(['a','b','c'])\n",
        "print(\"array shape: {}\".format(np_array.shape))\n",
        "print(np_array)\n",
        "print(\"second value of the array (np_array[1]): {}\".format(np_array[1]))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "serie shape: (3,)\n",
            "0    a\n",
            "1    b\n",
            "2    c\n",
            "dtype: object\n",
            "second value of the serie (serie[1]): b\n",
            "array shape: (3,)\n",
            "['a' 'b' 'c']\n",
            "second value of the array (np_array[1]): b\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkoumYny7h8s"
      },
      "source": [
        "As DataFrame is a two-dimensional data structure, it has columns and rows. Also a DataFrame has has two axes: \"`axis 0`\" and \"`axis 1`\":\n",
        "- \"`axis 0`\" represents rows \n",
        "- \"`axis 1`\" represents columns\n",
        "\n",
        "Moreover, in the example above we used the `[]` operator to access both a value the Series and a value in the one dimensional array. \n",
        "\n",
        "To access an element within DataFrame we need to provide two indexes (one per each axis). Also, instead of `[]` operator, we need to use `.loc()` or `.iloc()` indexers. We will see how to use the `[]` operator and `.loc()` or `.iloc()` indexers later in this notebook, but this point is going to be tackled more in detail in next notebooks.\n",
        "\n",
        "The takeaway so far is that:\n",
        "- Series object has only \"`axis 0`\" and we can access individual values using` []` operator\n",
        "- DataFrame object has `axis 0` (rows) and `axis 1` (cols) and individual values are accessed using `.loc()` or `iloc()` indexers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgnnwtdT1DcK"
      },
      "source": [
        "# Creating pandas DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrtWVzCj0_8Z"
      },
      "source": [
        "Pandas DataFrame can be created in [multiple ways](https://www.geeksforgeeks.org/different-ways-to-create-pandas-dataframe/). \n",
        "\n",
        "1. For example, we can call `pd.DataFrame(data=None, index=None, columns=None)` with `data` set to a numpy array, `index` set to a list of row names, and `column` set to a list of column names to create a Pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgM1Y2GQdvkx",
        "outputId": "865fc80e-daa4-4b23-ed4d-d7a42876290c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "numpy_data = np.array([np.arange(3), np.arange(3,6), np.arange(6,9), np.arange(9,12)], dtype = \"uint8\")\n",
        "print(\"This is the numpy array with the data: \\n {}\".format(numpy_data))\n",
        "\n",
        "df = pd.DataFrame(data=numpy_data, \n",
        "                  index=[\"index1\", \"index2\", \"index3\", \"index4\"],\n",
        "                  columns=[\"column1\", \"column2\", \"column3\"])\n",
        "print(\"This is the created Dataframe: \\n {}\".format(df))\n",
        "\n",
        "# Notice that the inferred dtype is uint8.\n",
        "print(\"Inferred dtype \\n{}\".format(df.dtypes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the numpy array with the data: \n",
            " [[ 0  1  2]\n",
            " [ 3  4  5]\n",
            " [ 6  7  8]\n",
            " [ 9 10 11]]\n",
            "This is the created Dataframe: \n",
            "         column1  column2  column3\n",
            "index1        0        1        2\n",
            "index2        3        4        5\n",
            "index3        6        7        8\n",
            "index4        9       10       11\n",
            "Inferred dtype \n",
            "column1    uint8\n",
            "column2    uint8\n",
            "column3    uint8\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa0_qG_inkt7"
      },
      "source": [
        "2. We can also create the DataFrame from a json structure. Note here that as pandas can export the data in multiple ways (included json) using `to_*` method, we can see how the json structure looks like. In this case, we are going to use `to_json()`:\n",
        "\n",
        "```python\n",
        "print(df.to_json())\n",
        "```\n",
        "The output is:\n",
        "\n",
        "```\n",
        "{\"column1\":{\"index1\":0,\"index2\":3,\"index3\":6,\"index4\":9},\"column2\":{\"index1\":1,\"index2\":4,\"index3\":7,\"index4\":10},\"column3\":{\"index1\":2,\"index2\":5,\"index3\":8,\"index4\":11}}\n",
        "```\n",
        "\n",
        "Therefore, we can create the same DataFrame as follows. Note that is not necessary to set both the `index` and `columns` because they are contained in the json structure:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpCiFK2FgyXh",
        "outputId": "a3abe2dc-aa06-4ec4-a415-7a4067f36d1f"
      },
      "source": [
        "data = {\"column1\":{\"index1\":0,\"index2\":3,\"index3\":6,\"index4\":9},\n",
        "        \"column2\":{\"index1\":1,\"index2\":4,\"index3\":7,\"index4\":10},\n",
        "        \"column3\":{\"index1\":2,\"index2\":5,\"index3\":8,\"index4\":11}}\n",
        "\n",
        "df_2 = pd.DataFrame(data=data)\n",
        "print(df_2)\n",
        "\n",
        "# Notice that the inferred dtype is int64.\n",
        "print(\"Inferred dtype \\n{}\".format(df_2.dtypes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        column1  column2  column3\n",
            "index1        0        1        2\n",
            "index2        3        4        5\n",
            "index3        6        7        8\n",
            "index4        9       10       11\n",
            "Inferred dtype \n",
            "column1    int64\n",
            "column2    int64\n",
            "column3    int64\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wf3b6VMypStE"
      },
      "source": [
        "3. We can also create the same DataFrame as follows. Note here that we have to include index set to a list of row names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bdgjRQ0h7Dl",
        "outputId": "2cd873f2-da92-45b3-b191-9ce2d9836d0f"
      },
      "source": [
        "data = {\"column1\":[0,3,6,9],\n",
        "        \"column2\":[1,4,7,10],\n",
        "        \"column3\":[2,5,8,11]}\n",
        "\n",
        "df_3 = pd.DataFrame(data=data, index=[\"index1\", \"index2\", \"index3\", \"index4\"])\n",
        "print(df_3)\n",
        "\n",
        "# Notice that the inferred dtype is int64.\n",
        "print(\"Inferred dtype \\n{}\".format(df_3.dtypes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        column1  column2  column3\n",
            "index1        0        1        2\n",
            "index2        3        4        5\n",
            "index3        6        7        8\n",
            "index4        9       10       11\n",
            "Inferred dtype \n",
            "column1    int64\n",
            "column2    int64\n",
            "column3    int64\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHTh5TLS0jYF"
      },
      "source": [
        "4. Moreover, we can also create a DataFrame using lists of lists as `data`. Here, we have to include both the `index` and `columns`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ntk-V1Njeao",
        "outputId": "b04b3ccf-9f22-45b2-ed1f-76ec1b9644dc"
      },
      "source": [
        "data = [[0,1,2],\n",
        "        [3,4,5],\n",
        "        [6,7,8],\n",
        "        [9,10,11]]\n",
        "\n",
        "df_4 = pd.DataFrame(data=data, \n",
        "                  index=[\"index1\", \"index2\", \"index3\", \"index4\"],\n",
        "                  columns=[\"column1\", \"column2\", \"column3\"])\n",
        "print(df_4)\n",
        "\n",
        "# Notice that the inferred dtype is int64.\n",
        "print(\"Inferred dtype \\n{}\".format(df_4.dtypes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        column1  column2  column3\n",
            "index1        0        1        2\n",
            "index2        3        4        5\n",
            "index3        6        7        8\n",
            "index4        9       10       11\n",
            "Inferred dtype \n",
            "column1    int64\n",
            "column2    int64\n",
            "column3    int64\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mHCleSF3qsH"
      },
      "source": [
        "To enforce a single `dtype` (single type for all the values):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kctNDpL3pEJ",
        "outputId": "99c1946c-89fc-44e9-b498-4241f6964a0a"
      },
      "source": [
        "df_uint8 = pd.DataFrame(data=data, \n",
        "                  index=[\"index1\", \"index2\", \"index3\", \"index4\"],\n",
        "                  columns=[\"column1\", \"column2\", \"column3\"],\n",
        "                  dtype=np.uint8)\n",
        "\n",
        "print(df_uint8)\n",
        "\n",
        "# Notice that the inferred dtype is int64.\n",
        "print(\"dtype \\n{}\".format(df_uint8.dtypes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        column1  column2  column3\n",
            "index1        0        1        2\n",
            "index2        3        4        5\n",
            "index3        6        7        8\n",
            "index4        9       10       11\n",
            "dtype \n",
            "column1    uint8\n",
            "column2    uint8\n",
            "column3    uint8\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HfuVx6H4TDQ"
      },
      "source": [
        "# DataFrame attributes\n",
        "\n",
        "DataFrame provides many attributes. For example and shown above, `dtype` is an example of attribute provided by DataFrame. Other attributes are shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4_cnLKC41ZH",
        "outputId": "feb32031-618c-4098-89f5-e75ccfa7f83b"
      },
      "source": [
        "numpy_data = np.array([np.arange(3), np.arange(3,6), np.arange(6,9), np.arange(9,12)])                 \n",
        "\n",
        "df = pd.DataFrame(data=numpy_data, \n",
        "                  index=[\"index1\", \"index2\", \"index3\", \"index4\"],\n",
        "                  columns=[\"column1\", \"column2\", \"column3\"])\n",
        "\n",
        "# dtypes: Return the dtypes in the DataFrame.\n",
        "print(\"dtypes \\n{}\\n\".format(df.dtypes))\n",
        "\n",
        "# shape: Return a tuple representing the dimensionality of the DataFrame.\n",
        "print(\"shape: {}\\n\".format(df.shape))\n",
        "\n",
        "# empty: Indicator whether DataFrame is empty.\n",
        "print(\"empty: {}\\n\".format(df.empty))\n",
        "\n",
        "# ndim: Return an int representing the number of axes / array dimensions.\n",
        "print(\"ndim: {}\\n\".format(df.ndim))\n",
        "\n",
        "# size: Return an int representing the number of elements in this object.\n",
        "print(\"size: {}\\n\".format(df.size))\n",
        "\n",
        "# values: Return a Numpy representation of the DataFrame.\n",
        "print(\"values: \\n{}\\n\".format(df.values))\n",
        "\n",
        "# attrs: Dictionary of global attributes of this dataset.\n",
        "# attrs is experimental and may change without warning.\n",
        "print(\"attrs: \\n{}\".format(df.attrs))\n",
        "print(\"df.attrs['mydata'] = 'myvalue'\")\n",
        "df.attrs['mydata'] = 'myvalue'\n",
        "print(\"attrs: \\n{}\\n\".format(df.attrs))\n",
        "\n",
        "# columns: The column labels of the DataFrame.\n",
        "print(\"columns: \\n{}\\n\".format(df.columns))\n",
        "print(\"columns.values: \\n{}\\n\".format(df.columns.values))\n",
        "\n",
        "# loc: Access a group of rows and columns by label(s) or a boolean array.\n",
        "# .loc[] is primarily label based, but may also be used with a boolean array.\n",
        "# Single label. Note this returns the row as a Series (e.g. df.loc['index1'])\n",
        "# List of labels. Note using [[]] returns a DataFrame (e.g. df.loc[['index1','index2']]):\n",
        "print(\"df.loc['index1']: \\n{}\\n\".format(df.loc['index1']))\n",
        "print(\"type(df.loc['index1']): {}\\n\".format(type(df.loc['index1'])))\n",
        "print(\"df.loc[['index1','index2']]: \\n{}\\n\".format(df.loc[['index1','index2']]))\n",
        "\n",
        "# iloc: Purely integer-location based indexing for selection by position.\n",
        "print(\"df.iloc[0]: \\n{}\\n\".format(df.iloc[0]))\n",
        "print(\"type(df.iloc[0]): {}\\n\".format(type(df.iloc[0])))\n",
        "print(\"df.iloc[[0]]: \\n{}\\n\".format(df.iloc[[0]]))\n",
        "print(\"df.iloc[[0, 1]]: \\n{}\\n\".format(df.iloc[[0, 1]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dtypes \n",
            "column1    int64\n",
            "column2    int64\n",
            "column3    int64\n",
            "dtype: object\n",
            "\n",
            "shape: (4, 3)\n",
            "\n",
            "empty: False\n",
            "\n",
            "ndim: 2\n",
            "\n",
            "size: 12\n",
            "\n",
            "values: \n",
            "[[ 0  1  2]\n",
            " [ 3  4  5]\n",
            " [ 6  7  8]\n",
            " [ 9 10 11]]\n",
            "\n",
            "attrs: \n",
            "{}\n",
            "df.attrs['mydata'] = 'myvalue'\n",
            "attrs: \n",
            "{'mydata': 'myvalue'}\n",
            "\n",
            "columns: \n",
            "Index(['column1', 'column2', 'column3'], dtype='object')\n",
            "\n",
            "columns.values: \n",
            "['column1' 'column2' 'column3']\n",
            "\n",
            "df.loc['index1']: \n",
            "column1    0\n",
            "column2    1\n",
            "column3    2\n",
            "Name: index1, dtype: int64\n",
            "\n",
            "type(df.loc['index1']): <class 'pandas.core.series.Series'>\n",
            "\n",
            "df.loc[['index1','index2']]: \n",
            "        column1  column2  column3\n",
            "index1        0        1        2\n",
            "index2        3        4        5\n",
            "\n",
            "df.iloc[0]: \n",
            "column1    0\n",
            "column2    1\n",
            "column3    2\n",
            "Name: index1, dtype: int64\n",
            "\n",
            "type(df.iloc[0]): <class 'pandas.core.series.Series'>\n",
            "\n",
            "df.iloc[[0]]: \n",
            "        column1  column2  column3\n",
            "index1        0        1        2\n",
            "\n",
            "df.iloc[[0, 1]]: \n",
            "        column1  column2  column3\n",
            "index1        0        1        2\n",
            "index2        3        4        5\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBNUWuPYYmAT"
      },
      "source": [
        "# DataFrame methods\n",
        "\n",
        "Some of the methods are shown as follows. But first, let's create a sample DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivEarJNqYroK"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "numpy_data = np.array([np.arange(3), np.arange(3,6), np.arange(6,9), np.arange(9,12)])                 \n",
        "\n",
        "df = pd.DataFrame(data=numpy_data, \n",
        "                  index=[\"index1\", \"index2\", \"index3\", \"index4\"],\n",
        "                  columns=[\"column1\", \"column2\", \"column3\"])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOpsHJDGjLbO"
      },
      "source": [
        "**Viewing your data**: The first thing we can do when exploring a DataFrame is to print the first `n` rows (`.head(n=5)`) or to print the last `n` rows (`.tail(n=5)`), where `n` (optional) is the number of rows to show. Therefore:\n",
        "\n",
        "*   [`DataFrame.head(n=5)`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html): Return the first `n` rows.  It is useful for quickly testing that your data is loaded correctly.\n",
        "\n",
        "*   [`DataFrame.tail(n=5)`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.tail.html#pandas.DataFrame.tail): Return the last `n` rows. It is useful for quickly verifying data, for example, after sorting or appending rows.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZQR88eMjvjl",
        "outputId": "deb966c9-78b1-4df3-ba61-a08a4b2c4e86"
      },
      "source": [
        "print(df.head(1))\n",
        "print(df.tail(2))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        column1  column2  column3\n",
            "index1        0        1        2\n",
            "        column1  column2  column3\n",
            "index3        6        7        8\n",
            "index4        9       10       11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk6096vdj3lA"
      },
      "source": [
        "**Getting information about the data**: This can be done using:\n",
        "\n",
        "*    `.info()`: provides a concise summary of your DataFrame. \n",
        "*   `.describe()`: returns a statistical summary\n",
        "*   `.describe(include='all')`: gives full summary statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFDZmJ7YlsIq",
        "outputId": "3f60e9bf-560d-49a7-e282-24d8f51889a1"
      },
      "source": [
        "# .info() provides the key details about your dataset:\n",
        "# (e.g. the number of rows and columns, the number of non-null values,\n",
        "# what type of data is in each column, how much memory your DataFrame is using)\n",
        "\n",
        "print(df.info())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 4 entries, index1 to index4\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype\n",
            "---  ------   --------------  -----\n",
            " 0   column1  4 non-null      int64\n",
            " 1   column2  4 non-null      int64\n",
            " 2   column3  4 non-null      int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 128.0+ bytes\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QjNaAStmsbq",
        "outputId": "119de787-3d8e-46c8-b0c3-a434db8bccc5"
      },
      "source": [
        "print(df.describe())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        column1    column2    column3\n",
            "count  4.000000   4.000000   4.000000\n",
            "mean   4.500000   5.500000   6.500000\n",
            "std    3.872983   3.872983   3.872983\n",
            "min    0.000000   1.000000   2.000000\n",
            "25%    2.250000   3.250000   4.250000\n",
            "50%    4.500000   5.500000   6.500000\n",
            "75%    6.750000   7.750000   8.750000\n",
            "max    9.000000  10.000000  11.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DelckH2hmw7f",
        "outputId": "d944e6e5-88f5-49f7-e2c6-6498d5fb3a15"
      },
      "source": [
        "print(df.describe(include='all'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        column1    column2    column3\n",
            "count  4.000000   4.000000   4.000000\n",
            "mean   4.500000   5.500000   6.500000\n",
            "std    3.872983   3.872983   3.872983\n",
            "min    0.000000   1.000000   2.000000\n",
            "25%    2.250000   3.250000   4.250000\n",
            "50%    4.500000   5.500000   6.500000\n",
            "75%    6.750000   7.750000   8.750000\n",
            "max    9.000000  10.000000  11.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA5M0lDMakKL"
      },
      "source": [
        "**Append rows**: `append(other[, ignore_index, …])`: Append rows of other to the end of caller, returning a new object. This means that using `append()` will return a copy without affecting the original DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6LR7OI5ah1p",
        "outputId": "a19391ea-99b4-46b3-c2d1-98720ed6140f"
      },
      "source": [
        "# append(other[, ignore_index, …]): Append rows of other to the end of caller, returning a new object.\n",
        "df_2 = df.loc[['index1','index2']]\n",
        "df_result = df.append(df_2)\n",
        "print(df_result)\n",
        "\n",
        "# With ignore_index set to True:\n",
        "df_result = df.append(df_2, ignore_index=True)\n",
        "print(df_result)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        column1  column2  column3\n",
            "index1        0        1        2\n",
            "index2        3        4        5\n",
            "index3        6        7        8\n",
            "index4        9       10       11\n",
            "index1        0        1        2\n",
            "index2        3        4        5\n",
            "   column1  column2  column3\n",
            "0        0        1        2\n",
            "1        3        4        5\n",
            "2        6        7        8\n",
            "3        9       10       11\n",
            "4        0        1        2\n",
            "5        3        4        5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGntjZV0ablR"
      },
      "source": [
        "**Insert column**: `insert(loc, column, value[, allow_duplicates])`: Insert column into DataFrame at specified location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmPxoPtSbVkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6999fe67-d48c-4c28-b6df-73d64f025e91"
      },
      "source": [
        "new_col = df['column1'] * 10\n",
        "print(new_col)\n",
        "df.insert(1, 'new_column', new_col)\n",
        "print(df)\n",
        "\n",
        "try:\n",
        "  df.insert(1, 'new_column', new_col)\n",
        "except ValueError:\n",
        "  print(\"\\n cannot insert a column already added \\n\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "index1     0\n",
            "index2    30\n",
            "index3    60\n",
            "index4    90\n",
            "Name: column1, dtype: int64\n",
            "        column1  new_column  column2  column3\n",
            "index1        0           0        1        2\n",
            "index2        3          30        4        5\n",
            "index3        6          60        7        8\n",
            "index4        9          90       10       11\n",
            "\n",
            " cannot insert a column already added \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPhuiAOF5Euk"
      },
      "source": [
        "**Handling duplicates**: Pandas `drop_duplicates()` method helps in removing duplicates from the DataFrame. `drop_duplicates()`  method returns DataFrame with duplicate rows removed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5_iMvBD6Trz",
        "outputId": "8ba092db-5966-4f59-fbf3-f240b8d329b0"
      },
      "source": [
        "# Let's see our DataFrame before removing duplicate rows\n",
        "print(df_result)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   column1  column2  column3\n",
            "0        0        1        2\n",
            "1        3        4        5\n",
            "2        6        7        8\n",
            "3        9       10       11\n",
            "4        0        1        2\n",
            "5        3        4        5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYllj9iV6z07",
        "outputId": "19505cdc-a08e-4a3f-b9c8-cf7d66a03eb5"
      },
      "source": [
        "# Remove duplicates calling drop_duplicates() with default behaviour:\n",
        "df_without_duplicates = df_result.drop_duplicates()\n",
        "print(df_without_duplicates)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   column1  column2  column3\n",
            "0        0        1        2\n",
            "1        3        4        5\n",
            "2        6        7        8\n",
            "3        9       10       11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI8YJfRa7WtK"
      },
      "source": [
        "As we can see, just like `append()`, the `drop_duplicates()` method will also return a copy of your DataFrame, but this time with duplicates removed. Using `inplace=True` will modify the DataFrame object in place. Let's check this point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3yt9VDK7pzY",
        "outputId": "b6478892-20fd-4dc8-a7a1-b6a2cb20240d"
      },
      "source": [
        "# Make a full copy of the df_result DataFame\n",
        "df_full_copy = df_result.copy()\n",
        "print(df_full_copy)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   column1  column2  column3\n",
            "0        0        1        2\n",
            "1        3        4        5\n",
            "2        6        7        8\n",
            "3        9       10       11\n",
            "4        0        1        2\n",
            "5        3        4        5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hPmawFX7_2E",
        "outputId": "38fa6c8d-6e2a-49a4-aa90-1a472aa61024"
      },
      "source": [
        "# Remove duplicates using inplace=True:\n",
        "df_full_copy.drop_duplicates(inplace=True)\n",
        "print(df_full_copy)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   column1  column2  column3\n",
            "0        0        1        2\n",
            "1        3        4        5\n",
            "2        6        7        8\n",
            "3        9       10       11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRZzlkaQ9jKh"
      },
      "source": [
        "Another important argument for `drop_duplicates()` is `keep`, which has three possible options:\n",
        "\n",
        "- `first`: (default) Drop duplicates except for the first occurrence.\n",
        "- `last`: Drop duplicates except for the last occurrence.\n",
        "- `False`: Drop all duplicates.\n",
        "\n",
        "Let's see `last` and `False` options for argument `keep` in `drop_duplicats()` method (`first` is the default behaviour of this method and was seen in the previous example)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2klBBZo9gUu",
        "outputId": "ec146b1c-eb86-40eb-e640-ca19604a6876"
      },
      "source": [
        "# Make a full copy of the df_result DataFame\n",
        "df_full_copy = df_result.copy()\n",
        "print(df_full_copy)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   column1  column2  column3\n",
            "0        0        1        2\n",
            "1        3        4        5\n",
            "2        6        7        8\n",
            "3        9       10       11\n",
            "4        0        1        2\n",
            "5        3        4        5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6UKoZtx-F2e",
        "outputId": "08e2cddd-e3cd-4a05-d9b4-80be71cd405a"
      },
      "source": [
        "# Remove duplicates using using inplace=True and keep='last'\n",
        "df_full_copy.drop_duplicates(inplace=True, keep='last')\n",
        "print(df_full_copy)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   column1  column2  column3\n",
            "2        6        7        8\n",
            "3        9       10       11\n",
            "4        0        1        2\n",
            "5        3        4        5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLPTSMGN-eV8",
        "outputId": "47b07cb9-fb30-4e18-979a-b20de31c78b1"
      },
      "source": [
        "# Make a full copy of the df_result DataFame\n",
        "df_full_copy = df_result.copy()\n",
        "print(df_full_copy)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   column1  column2  column3\n",
            "0        0        1        2\n",
            "1        3        4        5\n",
            "2        6        7        8\n",
            "3        9       10       11\n",
            "4        0        1        2\n",
            "5        3        4        5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idkAP61y-hId",
        "outputId": "96f7d426-71b9-4028-e700-78cc120e5da7"
      },
      "source": [
        "# Remove duplicates using using inplace=True and keep=False\n",
        "df_full_copy.drop_duplicates(inplace=True, keep=False)\n",
        "print(df_full_copy)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   column1  column2  column3\n",
            "2        6        7        8\n",
            "3        9       10       11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNiHALLI_KSy"
      },
      "source": [
        "**How to work with missing values**: When exploring data, you’ll most likely encounter missing or null values. Most commonly you'll see Python's None or NumPy's `np.nan`. There are two options in dealing with nulls:\n",
        "- Get rid of rows or columns with nulls\n",
        "- Replace nulls with non-null values, a technique known as imputation\n",
        "\n",
        "So let's create a DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jU_SyBEJCPCs",
        "outputId": "3ba11e49-05e2-4d6b-d4c9-5e8f233fe972"
      },
      "source": [
        "# Make a full copy of the df_result DataFame\n",
        "df_full_copy = df_result.copy()\n",
        "print(df_full_copy)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   column1  column2  column3\n",
            "0        0        1        2\n",
            "1        3        4        5\n",
            "2        6        7        8\n",
            "3        9       10       11\n",
            "4        0        1        2\n",
            "5        3        4        5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DhMENhSTg9u"
      },
      "source": [
        " We are going to create some missing (or null) values using either:\n",
        " - numpy's `np.nan`\n",
        " - Python `None`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeIKddTcDEJg",
        "outputId": "7f495866-9249-4a7b-9ef0-d12f1e9c0d51"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a list with some values (including some null values):\n",
        "my_list = [100, None, np.nan]\n",
        "\n",
        "# Create a Serie from the previous list:\n",
        "my_serie = pd.Series(my_list, index = df_full_copy.columns)\n",
        "print(\"This Serie (with NaN values) will be added: \\n{}\".format(my_serie))\n",
        "# This commented line will also work\n",
        "# my_serie = pd.Series(my_list, index = ['column1','column2', 'column3'])\n",
        "\n",
        "# Append the created row to the dataFrame:\n",
        "df_full_copy = df_full_copy.append(my_serie, ignore_index=True)\n",
        "\n",
        "print(df_full_copy)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This Serie (with NaN values) will be added: \n",
            "column1    100.0\n",
            "column2      NaN\n",
            "column3      NaN\n",
            "dtype: float64\n",
            "   column1  column2  column3\n",
            "0      0.0      1.0      2.0\n",
            "1      3.0      4.0      5.0\n",
            "2      6.0      7.0      8.0\n",
            "3      9.0     10.0     11.0\n",
            "4      0.0      1.0      2.0\n",
            "5      3.0      4.0      5.0\n",
            "6    100.0      NaN      NaN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VfDGPKWHRxI"
      },
      "source": [
        "Following previous approximation, we add several more rows with null values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MQwWPWtGbtw",
        "outputId": "aeca4fe7-502c-40a3-c304-9e8e4cfe34c5"
      },
      "source": [
        "# Create some lists with some NaN values:\n",
        "my_lists = [[100, np.nan, None], \n",
        "            [np.nan, np.nan, None],\n",
        "            [np.nan, 200, np.nan]]\n",
        "\n",
        "# Append these lists to the dataFrame:\n",
        "for my_list in my_lists:\n",
        "  my_serie = pd.Series(my_list, index = df_full_copy.columns)\n",
        "  df_full_copy = df_full_copy.append(my_serie, ignore_index=True)\n",
        "\n",
        "print(df_full_copy)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   column1  column2  column3\n",
            "0      0.0      1.0      2.0\n",
            "1      3.0      4.0      5.0\n",
            "2      6.0      7.0      8.0\n",
            "3      9.0     10.0     11.0\n",
            "4      0.0      1.0      2.0\n",
            "5      3.0      4.0      5.0\n",
            "6    100.0      NaN      NaN\n",
            "7    100.0      NaN      NaN\n",
            "8      NaN      NaN      NaN\n",
            "9      NaN    200.0      NaN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsw_7o54HujJ"
      },
      "source": [
        "To check what values in the DataFrame are null we can use `isnull()` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "TA-gr0VMHnr7",
        "outputId": "8df71784-9c6f-4284-825c-f26e057f0816"
      },
      "source": [
        "df_full_copy.isnull()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>column1</th>\n",
              "      <th>column2</th>\n",
              "      <th>column3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   column1  column2  column3\n",
              "0    False    False    False\n",
              "1    False    False    False\n",
              "2    False    False    False\n",
              "3    False    False    False\n",
              "4    False    False    False\n",
              "5    False    False    False\n",
              "6    False     True     True\n",
              "7    False     True     True\n",
              "8     True     True     True\n",
              "9     True    False     True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9ZZIkemIoiq"
      },
      "source": [
        "We usually want to know how many null values are in each column. Therefore we can count how many null values are for each column. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLk6P_GvH_Vb",
        "outputId": "c1d6ce3f-4a6d-47f3-9c80-44a1c1934e16"
      },
      "source": [
        "df_full_copy.isnull().sum(axis=0)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "column1    2\n",
              "column2    3\n",
              "column3    4\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_llL5gimVB2u"
      },
      "source": [
        "From the previous output, we can see that in all columns the are null values. `column3` is the column with more null values (`4`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iytrUDj_MLPB"
      },
      "source": [
        "To remember if you need to apply `axis=0` or `axis=1` as argument to an specific function: \n",
        "\n",
        "- `axis=0` to apply a method down each column\n",
        "- `axis=1` to apply a method across each row\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/albertofernandezvillan/computer-vision-and-deep-learning-course/main/assets/numpy_and_pandas_axes.jpg\">\n",
        "\n",
        "Previous figure can be seen [here](https://stackoverflow.com/questions/17079279/how-is-axis-indexed-in-numpys-array) or [here](https://stackoverflow.com/questions/25773245/ambiguity-in-pandas-dataframe-numpy-array-axis-definition)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ7opozuUixO"
      },
      "source": [
        "If we want to calculate how many null values are in each row:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcO0Nb3eUnQv",
        "outputId": "3cb2cf7b-69d3-4813-a1e8-3ad73a0e2211"
      },
      "source": [
        "df_full_copy.isnull().sum(axis=1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "5    0\n",
              "6    2\n",
              "7    2\n",
              "8    3\n",
              "9    2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZcz6A5DUzzY"
      },
      "source": [
        "From the previous output we can see that only the last rows have null values. At this point, once identified that we have both null values in some rows and all columns, we can: \n",
        "- Get rid of rows or columns with nulls\n",
        "- Replace nulls with non-null values, a technique known as imputation\n",
        "\n",
        "As a rule of thumb, removing null data is only suggested if you have a small amount of missing data, which can  be performed using `dropna()`. In this case, we are going to perform `dropna(axis=0)`, which drops all rows with a single null value, returnig a new DataFrame (without altering the original one) unless you specify `inplace=True`. You can also drop columns with null values by setting `axis=1`. Let's check this point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXKOtzZ3jLVm",
        "outputId": "318078c2-5363-4134-c08b-5fe344aba31a"
      },
      "source": [
        "print(\"DataFrame with null values:\")\n",
        "print(df_full_copy)\n",
        "print(\"Removing all rows with null values:\")\n",
        "df_without_nan = df_full_copy.dropna(axis=0)\n",
        "print(df_without_nan)\n",
        "print(\"Removing all columns with null values:\")\n",
        "# As it can be seen we obtain a Empty DataFrame\n",
        "df_without_nan = df_full_copy.dropna(axis=1)\n",
        "print(df_without_nan)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DataFrame with null values:\n",
            "   column1  column2  column3\n",
            "0      0.0      1.0      2.0\n",
            "1      3.0      4.0      5.0\n",
            "2      6.0      7.0      8.0\n",
            "3      9.0     10.0     11.0\n",
            "4      0.0      1.0      2.0\n",
            "5      3.0      4.0      5.0\n",
            "6    100.0      NaN      NaN\n",
            "7    100.0      NaN      NaN\n",
            "8      NaN      NaN      NaN\n",
            "9      NaN    200.0      NaN\n",
            "Removing all rows with null values:\n",
            "   column1  column2  column3\n",
            "0      0.0      1.0      2.0\n",
            "1      3.0      4.0      5.0\n",
            "2      6.0      7.0      8.0\n",
            "3      9.0     10.0     11.0\n",
            "4      0.0      1.0      2.0\n",
            "5      3.0      4.0      5.0\n",
            "Removing all columns with null values:\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce4F-9f0qYxa"
      },
      "source": [
        "Instead of removing rows/cols with null values, another option is to replace nulls with non-null values (imputation), like the mean or median for that specific column. As an example, we are going to replace all null values with an specific value (e.g. `123`).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyjneFYnwGlN",
        "outputId": "36b44df4-f0ed-48d2-a3be-0759d017b93e"
      },
      "source": [
        "print(\"DataFrame with null values:\")\n",
        "print(df_full_copy)\n",
        "print(\"DataFrame with all null values replaced with '123.0' value:\")\n",
        "df_without_nan = df_full_copy.copy()\n",
        "df_without_nan.fillna(123.0, inplace = True)\n",
        "print(df_without_nan)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DataFrame with null values:\n",
            "   column1  column2  column3\n",
            "0      0.0      1.0      2.0\n",
            "1      3.0      4.0      5.0\n",
            "2      6.0      7.0      8.0\n",
            "3      9.0     10.0     11.0\n",
            "4      0.0      1.0      2.0\n",
            "5      3.0      4.0      5.0\n",
            "6    100.0      NaN      NaN\n",
            "7    100.0      NaN      NaN\n",
            "8      NaN      NaN      NaN\n",
            "9      NaN    200.0      NaN\n",
            "DataFrame with all null values replaced with '123.0' value:\n",
            "   column1  column2  column3\n",
            "0      0.0      1.0      2.0\n",
            "1      3.0      4.0      5.0\n",
            "2      6.0      7.0      8.0\n",
            "3      9.0     10.0     11.0\n",
            "4      0.0      1.0      2.0\n",
            "5      3.0      4.0      5.0\n",
            "6    100.0    123.0    123.0\n",
            "7    100.0    123.0    123.0\n",
            "8    123.0    123.0    123.0\n",
            "9    123.0    200.0    123.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECTfhiMPwrST"
      },
      "source": [
        "We can also replace each null value with the mean value of each corresponding column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54883w_qsOGu",
        "outputId": "cd54a337-87c6-43a8-a90c-4815ac2843e4"
      },
      "source": [
        "print(\"DataFrame with null values:\")\n",
        "print(df_full_copy)\n",
        "\n",
        "print(\"DataFrame with non null values replaced with the mean:\")\n",
        "df_without_nan = df_full_copy.copy()\n",
        "mean_col_1 = df_without_nan['column1'].mean()\n",
        "mean_col_2 = df_without_nan['column2'].mean()\n",
        "mean_col_3 = df_without_nan['column3'].mean()\n",
        "\n",
        "df_without_nan[\"column1\"].fillna(mean_col_1, inplace = True)\n",
        "df_without_nan[\"column2\"].fillna(mean_col_2, inplace = True)\n",
        "df_without_nan[\"column3\"].fillna(mean_col_3, inplace = True)\n",
        "\n",
        "print(df_without_nan)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DataFrame with null values:\n",
            "   column1  column2  column3\n",
            "0      0.0      1.0      2.0\n",
            "1      3.0      4.0      5.0\n",
            "2      6.0      7.0      8.0\n",
            "3      9.0     10.0     11.0\n",
            "4      0.0      1.0      2.0\n",
            "5      3.0      4.0      5.0\n",
            "6    100.0      NaN      NaN\n",
            "7    100.0      NaN      NaN\n",
            "8      NaN      NaN      NaN\n",
            "9      NaN    200.0      NaN\n",
            "DataFrame with non null values replaced with the mean:\n",
            "   column1     column2  column3\n",
            "0    0.000    1.000000      2.0\n",
            "1    3.000    4.000000      5.0\n",
            "2    6.000    7.000000      8.0\n",
            "3    9.000   10.000000     11.0\n",
            "4    0.000    1.000000      2.0\n",
            "5    3.000    4.000000      5.0\n",
            "6  100.000   32.428571      5.5\n",
            "7  100.000   32.428571      5.5\n",
            "8   27.625   32.428571      5.5\n",
            "9   27.625  200.000000      5.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeCwY7iaxAHo"
      },
      "source": [
        "Previous functionallity can be performed in a more compact way as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mak3xFMyd8X",
        "outputId": "5ecc370d-a7f3-4a35-c44e-f5c80eefc6ed"
      },
      "source": [
        "print(\"DataFrame with null values\")\n",
        "df_without_nan = df_full_copy.copy()\n",
        "print(df_without_nan)\n",
        "\n",
        "# 1. Create a dictionary with 'column:value' pairs:\n",
        "means = df_without_nan[df_without_nan.columns].mean()\n",
        "columns = df_full_copy.columns\n",
        "\n",
        "values = {}\n",
        "for A, B in zip(columns, means):\n",
        "    values[A] = B\n",
        "\n",
        "print(\"\\nDict to be used to fill the null values \\n{}\\n\".format(values))\n",
        "\n",
        "print(\"DataFrame with non null values replaced with the mean:\")\n",
        "# 2. Use this dictionary to fill the null values:\n",
        "df_without_nan.fillna(value=values, inplace=True)\n",
        "print(df_without_nan)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DataFrame with null values\n",
            "   column1  column2  column3\n",
            "0      0.0      1.0      2.0\n",
            "1      3.0      4.0      5.0\n",
            "2      6.0      7.0      8.0\n",
            "3      9.0     10.0     11.0\n",
            "4      0.0      1.0      2.0\n",
            "5      3.0      4.0      5.0\n",
            "6    100.0      NaN      NaN\n",
            "7    100.0      NaN      NaN\n",
            "8      NaN      NaN      NaN\n",
            "9      NaN    200.0      NaN\n",
            "\n",
            "Dict to be used to fill the null values \n",
            "{'column1': 27.625, 'column2': 32.42857142857143, 'column3': 5.5}\n",
            "\n",
            "DataFrame with non null values replaced with the mean:\n",
            "   column1     column2  column3\n",
            "0    0.000    1.000000      2.0\n",
            "1    3.000    4.000000      5.0\n",
            "2    6.000    7.000000      8.0\n",
            "3    9.000   10.000000     11.0\n",
            "4    0.000    1.000000      2.0\n",
            "5    3.000    4.000000      5.0\n",
            "6  100.000   32.428571      5.5\n",
            "7  100.000   32.428571      5.5\n",
            "8   27.625   32.428571      5.5\n",
            "9   27.625  200.000000      5.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv3knGGk0kIz"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "In this notebook an introduction to pandas is given. See other notebooks for further information about pandas."
      ]
    }
  ]
}